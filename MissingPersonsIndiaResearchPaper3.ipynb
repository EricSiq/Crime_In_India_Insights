{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlVzGn5gm31YrVh4ycgzfO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EricSiq/India_Missing_Persons_Analysis_2017-2022/blob/main/MissingPersonsIndiaResearchPaper3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  **Problem Statement**\n",
        "Despite thousands of missing‑person cases reported each year in India, there is limited understanding of where these cases concentrate and why. Identifying geographic “hotspots” at the district level is critical for prioritizing law‑enforcement resources, guiding community outreach, and shaping preventive policy. Using India’s district‑wise missing‑person counts (2018–2022), along with demographic and socio‑economic covariates, we seek to build a data‑driven framework that:"
      ],
      "metadata": {
        "id": "4LuF8mtVoKRZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **Discovers latent spatial patterns** among districts with similar missing‑person profiles (age, gender, population-adjusted rates).\n",
        "2. **Predicts future hotspot risk** so that high‑risk districts can be flagged before case counts surge.\n",
        "\n",
        "By combining **unsupervised** and **supervised** machine‑learning techniques, our approach delivers both *exploratory insights* and *actionable predictions* for public‑safety stakeholders.\n",
        "\n",
        "---\n",
        "\n",
        "### How We’ll Use Unsupervised & Supervised Techniques\n",
        "\n",
        "1. **Unsupervised Exploration & Clustering**\n",
        "\n",
        "   * **Dimensionality Reduction** (PCA, UMAP, t‑SNE): Project 15+ features (gender‑age counts, per‑capita rates, socio‑economic indicators) into 2D/3D to visualize natural groupings and reveal hidden structure.\n",
        "   * **Clustering Algorithms** (K‑Means, DBSCAN, Agglomerative): Group districts into clusters representing low, medium, and high missing‑person incidence, plus outlier regions.  These clusters highlight *candidate hotspots* without using any labels.\n",
        "   * **Geospatial Mapping**: Overlay cluster assignments on India’s district map to pinpoint contiguous hotspot regions and detect cross‑state patterns.\n",
        "\n",
        "2. **Feature Engineering for Supervised Modeling**\n",
        "\n",
        "   * **Label Definition**: Define “hotspot” districts via a threshold (e.g. top 10 % of missing‑person rate per year) or by leveraging existing hotspot labels in the data.\n",
        "   * **Temporal Features**: Create lagged counts and rolling averages (2013–2022) to capture momentum in each district’s missing‑person rates.\n",
        "   * **Demographic & Socio‑Economic Covariates**: Include literacy rate, poverty index, crime data, urbanization level, and a binary flag for any transgender counts to enrich the model’s context.\n",
        "\n",
        "3. **Supervised Classification & Prediction**\n",
        "\n",
        "   * **Algorithms**: Train ensemble classifiers (Random Forest, XGBoost) using a **leave‑one‑year‑out** or **rolling‑window** cross‑validation so that each year (2013–2022) is tested exactly once.\n",
        "   * **Evaluation Metrics**: Focus on F1‑score and ROC‑AUC for the binary hotspot label (and PR‑AUC if hotspots are rare), tracking performance per held‑out year to detect concept drift.\n",
        "   * **Model Interpretability**: Use SHAP values to rank drivers of hotspot risk—e.g., whether rising adult‑female counts or socio‑economic indicators consistently predict new hotspots.\n",
        "\n",
        "4. **Hybrid Insights & Feedback**\n",
        "\n",
        "   * Feed unsupervised **cluster labels** back into the supervised model as an additional feature, allowing the classifier to learn from latent group structures.\n",
        "   * Compare hotspot predictions against cluster‑derived hotspots to validate consistency and uncover districts that clusters miss but the classifier flags (and vice versa).\n",
        "\n",
        "5. **Dynamic Hotspot Risk Mapping**\n",
        "\n",
        "   * Generate **annual choropleth maps** (2013–2022) of predicted risk scores and binary hotspots, using a fixed legend to visualize intensification or reduction of risk.\n",
        "   * Create an **interactive time‑slider dashboard** so policymakers can track emerging hotspots and allocate resources proactively.\n",
        "\n",
        "6. **Policy & Resource Allocation**\n",
        "\n",
        "   * Identify **persistent hotspots** (districts flagged in ≥ N consecutive years) for long‑term intervention programs.\n",
        "   * Detect **emerging hotspots** (districts newly flagged) to trigger rapid-response measures.\n",
        "   * Provide **explainable drivers** of risk per region, enabling targeted socio‑economic or legal reforms (e.g. improved awareness in high‑migration corridors or enhanced community support in low‑literacy areas).\n",
        "\n",
        "This combined unsupervised–supervised pipeline delivers a **comprehensive, data‑backed strategy** for hotspot identification, empowering Indian public‑safety authorities to act with precision and foresight.\n"
      ],
      "metadata": {
        "id": "ApLV_3Vxp-fF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Our Kaggle Dataset: 5 Years Districtwise India Missing Person's Dataset](https://www.kaggle.com/datasets/ericsiq/india-5-years-districtwise-missing-persons-dataset)\n",
        "\n",
        "\n",
        "[Our GitHub Repo](https://github.com/EricSiq/India_Missing_Persons_Analysis_2017-2022)"
      ],
      "metadata": {
        "id": "SMZi4UatqCl3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Libraries Used:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jdrO-hIwqHFV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Python Libraries**"
      ],
      "metadata": {
        "id": "KGNHlrQyqNbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd         # For data manipulation and analysis\n",
        "import numpy as np          # For numerical operations\n",
        "import seaborn as sns       #For visualisation & graphing\n",
        "import matplotlib.pyplot as plt  # For plotting graphs\n",
        "import seaborn as sns       # For enhanced visualization\n",
        "from tabulate import tabulate #For tabular outputs\n",
        "from sklearn.preprocessing import StandardScaler # For Feature scaling\n",
        "from sklearn.preprocessing import RobustScaler # For feature scaling\n",
        "from sklearn.metrics import silhouette_score #Accuracy Metrics\n",
        "from sklearn.decomposition import PCA #For graphical representation\n",
        "from sklearn.cluster import KMeans #For k means clustering\n",
        "from sklearn.neighbors import NearestNeighbors #For validating DBSCAN\n",
        "from sklearn.cluster import DBSCAN #For DBSCAN operations\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score #Accuracy metrics\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage #For validating Agglomerative Clustering\n",
        "from sklearn.cluster import AgglomerativeClustering #For Agglomerative clustering operationg\n",
        "from sklearn.metrics.pairwise import euclidean_distances #for validating divisive clustering"
      ],
      "metadata": {
        "id": "K2UjiVNXeiJ-"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Setting a style for seaborn plots\n",
        "sns.set(style=\"whitegrid\")"
      ],
      "metadata": {
        "id": "4j2Ya27Qej4E"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Data Loading\n",
        "\n",
        "\n",
        "\n",
        "> Upon loading of the datasets, it is noticed there is a serious disrepancy between column values for age groups.\n",
        "\n",
        "\n",
        "\n",
        "The age group classifications differ notably between the 2018–2020 and 2021–2022 datasets:\n",
        "\n",
        "\n",
        "2018–2020: Age brackets are more granular and traditional:\n",
        "\n",
        "Below 5 years\n",
        "\n",
        "5–14 years\n",
        "\n",
        "14–18 years\n",
        "\n",
        "18–30 years\n",
        "\n",
        "30–45 years\n",
        "\n",
        "45–60 years\n",
        "\n",
        "60 years & above\n",
        "\n",
        "\n",
        "\n",
        "In 2021–2022: The classification structure has changed:\n",
        "\n",
        "Below 12 years\n",
        "\n",
        "12–16 years\n",
        "\n",
        "16–18 years\n",
        "\n",
        "18 years & above"
      ],
      "metadata": {
        "id": "hoE4kZSzqRsc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "QIko8WuCdeV4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Section 1: Define file paths for each year's data.\n",
        "file_paths = {\n",
        "    2018: \"/content/DistrictwiseMissingPersons2018.csv\",\n",
        "    2019: \"/content/DistrictwiseMissingPersons2019.csv\",\n",
        "    2020: \"/content/DistrictwiseMissingPersons2020.csv\",\n",
        "    2021: \"/content/DistrictwiseMissingPersons2021.csv\",\n",
        "    2022: \"/content/DistrictwiseMissingPersons2022.csv\"\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Due to disrepancies between columns, we need to remove unnessessary columns and make them uniform across 2018-2022 years.\n",
        "\n",
        "> We have to group all age groups into either Children or 18+ age groups to simplify the age groups.\n",
        "\n"
      ],
      "metadata": {
        "id": "GuG_JzDKqZTu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#   Data Cleaning:\n",
        "1.     - Reading the CSV files into pandas dataframes.\n",
        "2.     - Removing Unnessessary Column values\n",
        "3.     - Examining initial structure & description of the data."
      ],
      "metadata": {
        "id": "0SAqbx6jqeDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# A list to hold all processed DataFrames.\n",
        "dfs = []\n",
        "\n",
        "# Section 2: Process each dataset according to its year.\n",
        "for year, path in file_paths.items():\n",
        "    # Load file with fallback encoding if necessary\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "    except UnicodeDecodeError:\n",
        "        try:\n",
        "            df = pd.read_csv(path, encoding='ISO-8859-1')\n",
        "            print(f\"Used fallback encoding for {year}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to load {year}: {e}\")\n",
        "            continue\n",
        "    # Define  region‐mapping function\n",
        "    def map_region(state):\n",
        "        south      = [\"Andhra Pradesh\", \"Telangana\", \"Karnataka\", \"Tamil Nadu\", \"Kerala\", \"Puducherry\", \"Lakshadweep\", \"AN Islands\"]\n",
        "        west       = [\"Maharashtra\", \"Goa\", \"Gujarat\", \"Daman and Diu\", \"DN Haveli and Daman Diu\"]\n",
        "        northeast  = [\"Arunachal Pradesh\", \"Assam\", \"Manipur\", \"Meghalaya\", \"Mizoram\", \"Nagaland\", \"Tripura\", \"Sikkim\"]\n",
        "        north      = [\"Kashmir\", \"Himachal Pradesh\", \"Punjab\", \"Uttarakhand\",\n",
        "                      \"Haryana\", \"Uttar Pradesh\", \"Rajasthan\", \"Bihar\",\n",
        "                      \"Chhattisgarh\", \"West Bengal\", \"Odisha\", \"Chandigarh\",\n",
        "                      \"Delhi\", \"Ladakh\", \"Jharkhand\", \"Madhya Pradesh\"]\n",
        "        state = state.strip()  # remove leading/trailing whitespace\n",
        "        if state in south:\n",
        "            return \"South India\"\n",
        "        elif state in west:\n",
        "            return \"West Coast\"\n",
        "        elif state in northeast:\n",
        "            return \"North East\"\n",
        "        elif state in north:\n",
        "            return \"North India\"\n",
        "        else:\n",
        "            return \"Other\"\n",
        "\n",
        "\n",
        "    # 2) Strip whitespace from the State column\n",
        "    df['State'] = df['State'].astype(str).str.strip()\n",
        "\n",
        "    # 3) Compute the region values\n",
        "    region_series = df['State'].map(map_region)\n",
        "\n",
        "    # 4) Insert the new column at position 2 (i.e. after Year at idx 0, State at idx 1)\n",
        "    df.insert(loc=2, column='Region', value=region_series)\n",
        "\n",
        "    # Now df.columns will be: ['Year', 'State', 'Region', 'District', …]\n",
        "\n",
        "    # Add the year column if not already present.\n",
        "    df['Year'] = year\n",
        "\n",
        "    # Remove any leading/trailing whitespace from column headers.\n",
        "    df.columns = df.columns.str.strip()\n",
        "\n",
        "    if year <= 2020:\n",
        "        # For datasets 2018-2020, we have the detailed age-group columns.\n",
        "        # Male columns\n",
        "        male_below_18 = [\n",
        "            'Male_Below_5_years',\n",
        "            'Male_5_years_&_Above_Below_14_years',\n",
        "            'Male_14_years_&_Above_Below_18_years'\n",
        "        ]\n",
        "        male_above_18 = [\n",
        "            'Male_18_years_&_Above_Below_30_years',\n",
        "            'Male_30_years_&_Above_Below_45_years',\n",
        "            'Male_45_years_&_Above_Below_60_years',\n",
        "            'Male_60_years_&_Above'\n",
        "        ]\n",
        "\n",
        "        # Female columns\n",
        "        female_below_18 = [\n",
        "            'Female_Below_5_years',\n",
        "            'Female_5_years_&_Above_Below_14_years',\n",
        "            'Female_14_years_&_Above_Below_18_years'\n",
        "        ]\n",
        "        female_above_18 = [\n",
        "            'Female_18_years_&_Above_Below_30_years',\n",
        "            'Female_30_years_&_Above_Below_45_years',\n",
        "            'Female_45_years_&_Above_Below_60_years',\n",
        "            'Female_60_years_&_Above'\n",
        "        ]\n",
        "\n",
        "        # Transgender columns\n",
        "        trans_below_18 = [\n",
        "            'Transgender_Below_5_years',\n",
        "            'Transgender_5_years_&_Above_Below_14_years',\n",
        "            'Transgender_14_years_&_Above_Below_18_years'\n",
        "        ]\n",
        "        trans_above_18 = [\n",
        "            'Transgender_18_years_&_Above_Below_30_years',\n",
        "            'Transgender_30_years_&_Above_Below_45_years',\n",
        "            'Transgender_45_years_&_Above_Below_60_years',\n",
        "            'Transgender_60_years_&_Above'\n",
        "        ]\n",
        "\n",
        "        # Total columns\n",
        "        total_below_18 = [\n",
        "            'Total_Below_5_years',\n",
        "            'Total_5_years_&_Above_Below_14_years',\n",
        "            'Total_14_years_&_Above_Below_18_years'\n",
        "        ]\n",
        "        total_above_18 = [\n",
        "            'Total_18_years_&_Above_Below_30_years',\n",
        "            'Total_30_years_&_Above_Below_45_years',\n",
        "            'Total_45_years_&_Above_Below_60_years',\n",
        "            'Total_60_years_&_Above'\n",
        "        ]\n",
        "\n",
        "        # Sum up the relevant columns for each group.\n",
        "        df['Male_Below_18'] = df[male_below_18].sum(axis=1)\n",
        "        df['Male_18_and_above'] = df[male_above_18].sum(axis=1)\n",
        "\n",
        "        df['Female_Below_18'] = df[female_below_18].sum(axis=1)\n",
        "        df['Female_18_and_above'] = df[female_above_18].sum(axis=1)\n",
        "\n",
        "        df['Transgender_Below_18'] = df[trans_below_18].sum(axis=1)\n",
        "        df['Transgender_18_and_above'] = df[trans_above_18].sum(axis=1)\n",
        "\n",
        "        df['Total_Below_18'] = df[total_below_18].sum(axis=1)\n",
        "        df['Total_18_and_above'] = df[total_above_18].sum(axis=1)\n",
        "\n",
        "        # Drop the original detailed columns.\n",
        "        drop_cols = (male_below_18 + male_above_18 +\n",
        "                     female_below_18 + female_above_18 +\n",
        "                     trans_below_18 + trans_above_18 +\n",
        "                     total_below_18 + total_above_18)\n",
        "        df.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
        "\n",
        "    else:\n",
        "        # For 2021-2022, the files already include aggregated age-group columns.\n",
        "        # Rename them to standardized names.\n",
        "        rename_map = {\n",
        "            'Male_Children': 'Male_Below_18',\n",
        "            'Male_18_years_&_Above': 'Male_18_and_above',\n",
        "            'Female_Children': 'Female_Below_18',\n",
        "            'Female_18_years_&_Above': 'Female_18_and_above',\n",
        "            'Transgender_Children': 'Transgender_Below_18',\n",
        "            'Transgender_18_years_&_Above': 'Transgender_18_and_above',\n",
        "            'Total_Children': 'Total_Below_18',\n",
        "            'Total_18_years_&_Above': 'Total_18_and_above'\n",
        "        }\n",
        "        df.rename(columns=rename_map, inplace=True)\n",
        "\n",
        "        # Drop any extra detailed age-group columns that are not needed.\n",
        "        drop_cols = [\n",
        "            'Male_Below_12_years', 'Male_12_years_&_Above_Below_16_years', 'Male_16_years_&_Above_Below_18_years',\n",
        "            'Female_Below_12_years', 'Female_12_years_&_Above_Below_16_years', 'Female_16_years_&_Above_Below_18_years',\n",
        "            'Transgender_Below_12_years', 'Transgender_12_years_&_Above_Below_16_years', 'Transgender_16_years_&_Above_Below_18_years',\n",
        "            'Total_Below_12_years', 'Total_12_years_&_Above_Below_14_years', 'Total_14_years_&_Above_Below_18_years'\n",
        "        ]\n",
        "        df.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
        "\n",
        "    # Append the processed DataFrame to our list.\n",
        "    dfs.append(df)\n",
        "    print(f\"Loaded and processed data for {year} with shape: {df.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjYpVieUe_eG",
        "outputId": "a26a6939-de8b-4472-e030-7b3942de4fb1"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded and processed data for 2018 with shape: (892, 16)\n",
            "Loaded and processed data for 2019 with shape: (912, 16)\n",
            "Loaded and processed data for 2020 with shape: (932, 16)\n",
            "Loaded and processed data for 2021 with shape: (941, 16)\n",
            "Loaded and processed data for 2022 with shape: (969, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# A list to hold all processed DataFrames.\n",
        "dfs = []\n",
        "\n",
        "# Section 2: Process each dataset according to its year.\n",
        "for year, path in file_paths.items():\n",
        "    # Load file with fallback encoding if necessary\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "    except UnicodeDecodeError:\n",
        "        try:\n",
        "            df = pd.read_csv(path, encoding='ISO-8859-1')\n",
        "            print(f\"Used fallback encoding for {year}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to load {year}: {e}\")\n",
        "            continue\n",
        "    # Define  region‐mapping function\n",
        "    def map_region(state):\n",
        "        south      = [\"Andhra Pradesh\", \"Telangana\", \"Karnataka\", \"Tamil Nadu\", \"Kerala\", \"Puducherry\", \"Lakshadweep\", \"AN Islands\"]\n",
        "        west       = [\"Maharashtra\", \"Goa\", \"Gujarat\", \"Daman and Diu\", \"DN Haveli and Daman Diu\"]\n",
        "        northeast  = [\"Arunachal Pradesh\", \"Assam\", \"Manipur\", \"Meghalaya\", \"Mizoram\", \"Nagaland\", \"Tripura\", \"Sikkim\"]\n",
        "        north      = [\"Kashmir\", \"Himachal Pradesh\", \"Punjab\", \"Uttarakhand\",\n",
        "                      \"Haryana\", \"Uttar Pradesh\", \"Rajasthan\", \"Bihar\",\n",
        "                      \"Chhattisgarh\", \"West Bengal\", \"Odisha\", \"Chandigarh\",\n",
        "                      \"Delhi\", \"Ladakh\", \"Jharkhand\", \"Madhya Pradesh\"]\n",
        "        state = state.strip()  # remove leading/trailing whitespace\n",
        "        if state in south:\n",
        "            return \"South India\"\n",
        "        elif state in west:\n",
        "            return \"West Coast\"\n",
        "        elif state in northeast:\n",
        "            return \"North East\"\n",
        "        elif state in north:\n",
        "            return \"North India\"\n",
        "        else:\n",
        "            return \"Other\"\n",
        "\n",
        "\n",
        "    # 2) Strip whitespace from the State column\n",
        "    df['State'] = df['State'].astype(str).str.strip()\n",
        "\n",
        "    # 3) Compute the region values\n",
        "    region_series = df['State'].map(map_region)\n",
        "\n",
        "    # 4) Insert the new column at position 2 (i.e. after Year at idx 0, State at idx 1)\n",
        "    df.insert(loc=2, column='Region', value=region_series)\n",
        "\n",
        "    # Now df.columns will be: ['Year', 'State', 'Region', 'District', …]\n",
        "\n",
        "    # Add the year column if not already present.\n",
        "    df['Year'] = year\n",
        "\n",
        "    # Remove any leading/trailing whitespace from column headers.\n",
        "    df.columns = df.columns.str.strip()\n",
        "\n",
        "    if year <= 2020:\n",
        "        # For datasets 2018-2020, we have the detailed age-group columns.\n",
        "        # Male columns\n",
        "        male_below_18 = [\n",
        "            'Male_Below_5_years',\n",
        "            'Male_5_years_&_Above_Below_14_years',\n",
        "            'Male_14_years_&_Above_Below_18_years'\n",
        "        ]\n",
        "        male_above_18 = [\n",
        "            'Male_18_years_&_Above_Below_30_years',\n",
        "            'Male_30_years_&_Above_Below_45_years',\n",
        "            'Male_45_years_&_Above_Below_60_years',\n",
        "            'Male_60_years_&_Above'\n",
        "        ]\n",
        "\n",
        "        # Female columns\n",
        "        female_below_18 = [\n",
        "            'Female_Below_5_years',\n",
        "            'Female_5_years_&_Above_Below_14_years',\n",
        "            'Female_14_years_&_Above_Below_18_years'\n",
        "        ]\n",
        "        female_above_18 = [\n",
        "            'Female_18_years_&_Above_Below_30_years',\n",
        "            'Female_30_years_&_Above_Below_45_years',\n",
        "            'Female_45_years_&_Above_Below_60_years',\n",
        "            'Female_60_years_&_Above'\n",
        "        ]\n",
        "\n",
        "        # Transgender columns\n",
        "        trans_below_18 = [\n",
        "            'Transgender_Below_5_years',\n",
        "            'Transgender_5_years_&_Above_Below_14_years',\n",
        "            'Transgender_14_years_&_Above_Below_18_years'\n",
        "        ]\n",
        "        trans_above_18 = [\n",
        "            'Transgender_18_years_&_Above_Below_30_years',\n",
        "            'Transgender_30_years_&_Above_Below_45_years',\n",
        "            'Transgender_45_years_&_Above_Below_60_years',\n",
        "            'Transgender_60_years_&_Above'\n",
        "        ]\n",
        "\n",
        "        # Total columns\n",
        "        total_below_18 = [\n",
        "            'Total_Below_5_years',\n",
        "            'Total_5_years_&_Above_Below_14_years',\n",
        "            'Total_14_years_&_Above_Below_18_years'\n",
        "        ]\n",
        "        total_above_18 = [\n",
        "            'Total_18_years_&_Above_Below_30_years',\n",
        "            'Total_30_years_&_Above_Below_45_years',\n",
        "            'Total_45_years_&_Above_Below_60_years',\n",
        "            'Total_60_years_&_Above'\n",
        "        ]\n",
        "\n",
        "        # Sum up the relevant columns for each group.\n",
        "        df['Male_Below_18'] = df[male_below_18].sum(axis=1)\n",
        "        df['Male_18_and_above'] = df[male_above_18].sum(axis=1)\n",
        "\n",
        "        df['Female_Below_18'] = df[female_below_18].sum(axis=1)\n",
        "        df['Female_18_and_above'] = df[female_above_18].sum(axis=1)\n",
        "\n",
        "        df['Transgender_Below_18'] = df[trans_below_18].sum(axis=1)\n",
        "        df['Transgender_18_and_above'] = df[trans_above_18].sum(axis=1)\n",
        "\n",
        "        df['Total_Below_18'] = df[total_below_18].sum(axis=1)\n",
        "        df['Total_18_and_above'] = df[total_above_18].sum(axis=1)\n",
        "\n",
        "        # Drop the original detailed columns.\n",
        "        drop_cols = (male_below_18 + male_above_18 +\n",
        "                     female_below_18 + female_above_18 +\n",
        "                     trans_below_18 + trans_above_18 +\n",
        "                     total_below_18 + total_above_18)\n",
        "        df.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
        "\n",
        "    else:\n",
        "        # For 2021-2022, the files already include aggregated age-group columns.\n",
        "        # Rename them to standardized names.\n",
        "        rename_map = {\n",
        "            'Male_Children': 'Male_Below_18',\n",
        "            'Male_18_years_&_Above': 'Male_18_and_above',\n",
        "            'Female_Children': 'Female_Below_18',\n",
        "            'Female_18_years_&_Above': 'Female_18_and_above',\n",
        "            'Transgender_Children': 'Transgender_Below_18',\n",
        "            'Transgender_18_years_&_Above': 'Transgender_18_and_above',\n",
        "            'Total_Children': 'Total_Below_18',\n",
        "            'Total_18_years_&_Above': 'Total_18_and_above'\n",
        "        }\n",
        "        df.rename(columns=rename_map, inplace=True)\n",
        "\n",
        "        # Drop any extra detailed age-group columns that are not needed.\n",
        "        drop_cols = [\n",
        "            'Male_Below_12_years', 'Male_12_years_&_Above_Below_16_years', 'Male_16_years_&_Above_Below_18_years',\n",
        "            'Female_Below_12_years', 'Female_12_years_&_Above_Below_16_years', 'Female_16_years_&_Above_Below_18_years',\n",
        "            'Transgender_Below_12_years', 'Transgender_12_years_&_Above_Below_16_years', 'Transgender_16_years_&_Above_Below_18_years',\n",
        "            'Total_Below_12_years', 'Total_12_years_&_Above_Below_14_years', 'Total_14_years_&_Above_Below_18_years'\n",
        "        ]\n",
        "        df.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
        "\n",
        "    # Append the processed DataFrame to our list.\n",
        "    dfs.append(df)\n",
        "    print(f\"Loaded and processed data for {year} with shape: {df.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0646fa93-f489-4117-a615-7eb4b8326d32",
        "id": "ZX32C-_Kzxtw"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded and processed data for 2018 with shape: (892, 16)\n",
            "Loaded and processed data for 2019 with shape: (912, 16)\n",
            "Loaded and processed data for 2020 with shape: (932, 16)\n",
            "Loaded and processed data for 2021 with shape: (941, 16)\n",
            "Loaded and processed data for 2022 with shape: (969, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  display a preview of the first processed DataFrame.\n",
        "print(\"\\nPreview of the processed dataset for the first file:\")\n",
        "print(tabulate(dfs[0].head(10), headers='keys', tablefmt='pretty'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTzhDiWTg0OO",
        "outputId": "911815b9-278d-4740-d4d8-9104160a593f"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Preview of the processed dataset for the first file:\n",
            "+---+------+----------------+-------------+------------------+------------+--------------+-------------------+-------------+---------------+-------------------+-----------------+---------------------+----------------------+--------------------------+----------------+--------------------+\n",
            "|   | Year |     State      |   Region    |     District     | Total_Male | Total_Female | Total_Transgender | Grand_Total | Male_Below_18 | Male_18_and_above | Female_Below_18 | Female_18_and_above | Transgender_Below_18 | Transgender_18_and_above | Total_Below_18 | Total_18_and_above |\n",
            "+---+------+----------------+-------------+------------------+------------+--------------+-------------------+-------------+---------------+-------------------+-----------------+---------------------+----------------------+--------------------------+----------------+--------------------+\n",
            "| 0 | 2018 | Andhra Pradesh | South India |    Anantapur     |    186     |     655      |         0         |     841     |      46       |       140.0       |       232       |         423         |          0           |            0             |      278       |        563         |\n",
            "| 1 | 2018 | Andhra Pradesh | South India |     Chittoor     |     93     |     354      |         0         |     447     |      37       |       56.0        |       138       |         216         |          0           |            0             |      175       |        272         |\n",
            "| 2 | 2018 | Andhra Pradesh | South India |     Cuddapah     |     66     |     156      |         0         |     222     |      26       |       40.0        |       58        |         98          |          0           |            0             |       84       |        138         |\n",
            "| 3 | 2018 | Andhra Pradesh | South India |  East Godavari   |    281     |     411      |         0         |     692     |      71       |       210.0       |       157       |         254         |          0           |            0             |      228       |        464         |\n",
            "| 4 | 2018 | Andhra Pradesh | South India | Guntakal Railway |     9      |      9       |         0         |     18      |       2       |        7.0        |        1        |          8          |          0           |            0             |       3        |         15         |\n",
            "| 5 | 2018 | Andhra Pradesh | South India |      Guntur      |    247     |     348      |         0         |     595     |      86       |       161.0       |       73        |         275         |          0           |            0             |      159       |        436         |\n",
            "| 6 | 2018 | Andhra Pradesh | South India |   Guntur Urban   |    202     |     293      |         0         |     495     |      43       |       159.0       |       46        |         247         |          0           |            0             |       89       |        406         |\n",
            "| 7 | 2018 | Andhra Pradesh | South India |     Krishna      |    156     |     264      |         0         |     420     |      19       |       137.0       |       17        |         247         |          0           |            0             |       36       |        384         |\n",
            "| 8 | 2018 | Andhra Pradesh | South India |     Kurnool      |    153     |     359      |         0         |     512     |      64       |       89.0        |       149       |         210         |          0           |            0             |      213       |        299         |\n",
            "| 9 | 2018 | Andhra Pradesh | South India |     Nellore      |    156     |     332      |        488        |     976     |      33       |       123.0       |       99        |         233         |         132          |           356            |      264       |        712         |\n",
            "+---+------+----------------+-------------+------------------+------------+--------------+-------------------+-------------+---------------+-------------------+-----------------+---------------------+----------------------+--------------------------+----------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tabulate(dfs[1].head(10), headers='keys', tablefmt='pretty'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQSSR0X4g2lE",
        "outputId": "c98c2f95-c952-4784-8b9d-1d2973642949"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+----------------+-------------+------------------+------------+--------------+-------------------+-------------+---------------+-------------------+-----------------+---------------------+----------------------+--------------------------+----------------+--------------------+\n",
            "|   | Year |     State      |   Region    |     District     | Total_Male | Total_Female | Total_Transgender | Grand_Total | Male_Below_18 | Male_18_and_above | Female_Below_18 | Female_18_and_above | Transgender_Below_18 | Transgender_18_and_above | Total_Below_18 | Total_18_and_above |\n",
            "+---+------+----------------+-------------+------------------+------------+--------------+-------------------+-------------+---------------+-------------------+-----------------+---------------------+----------------------+--------------------------+----------------+--------------------+\n",
            "| 0 | 2019 | Andhra Pradesh | South India |    Anantapur     |    257     |     766      |         0         |    1023     |      60       |        197        |       280       |        486.0        |          0           |            0             |      340       |        683         |\n",
            "| 1 | 2019 | Andhra Pradesh | South India |     Chittoor     |     99     |     319      |         0         |     418     |      44       |        55         |       151       |        168.0        |          0           |            0             |      195       |        223         |\n",
            "| 2 | 2019 | Andhra Pradesh | South India |     Cuddapah     |    163     |     475      |         0         |     638     |      52       |        111        |       176       |        299.0        |          0           |            0             |      228       |        410         |\n",
            "| 3 | 2019 | Andhra Pradesh | South India |  East Godavari   |    215     |     359      |         9         |     583     |      27       |        188        |       102       |        257.0        |          9           |            0             |      138       |        445         |\n",
            "| 4 | 2019 | Andhra Pradesh | South India | Guntakal Railway |     6      |      4       |         0         |     10      |       1       |         5         |        0        |         4.0         |          0           |            0             |       1        |         9          |\n",
            "| 5 | 2019 | Andhra Pradesh | South India |      Guntur      |    279     |     440      |         0         |     719     |      85       |        194        |       113       |        327.0        |          0           |            0             |      198       |        521         |\n",
            "| 6 | 2019 | Andhra Pradesh | South India |   Guntur Urban   |    202     |     293      |         0         |     495     |      43       |        159        |       46        |        247.0        |          0           |            0             |       89       |        406         |\n",
            "| 7 | 2019 | Andhra Pradesh | South India |     Krishna      |    182     |     282      |         0         |     464     |      13       |        169        |       27        |        255.0        |          0           |            0             |       40       |        424         |\n",
            "| 8 | 2019 | Andhra Pradesh | South India |     Kurnool      |    205     |     504      |         0         |     709     |      43       |        162        |       174       |        330.0        |          0           |            0             |      217       |        492         |\n",
            "| 9 | 2019 | Andhra Pradesh | South India |     Nellore      |    141     |     345      |         0         |     486     |      36       |        105        |       111       |        234.0        |          0           |            0             |      147       |        339         |\n",
            "+---+------+----------------+-------------+------------------+------------+--------------+-------------------+-------------+---------------+-------------------+-----------------+---------------------+----------------------+--------------------------+----------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tabulate(dfs[2].head(10), headers='keys', tablefmt='pretty'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZmbGNX_noQR",
        "outputId": "14a78241-cfdf-4b29-ffae-7fe00f54d223"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+----------------+-------------+---------------+------------+--------------+-------------------+-------------+---------------+-------------------+-----------------+---------------------+----------------------+--------------------------+----------------+--------------------+\n",
            "|   | Year |     State      |   Region    |   District    | Total_Male | Total_Female | Total_Transgender | Grand_Total | Male_Below_18 | Male_18_and_above | Female_Below_18 | Female_18_and_above | Transgender_Below_18 | Transgender_18_and_above | Total_Below_18 | Total_18_and_above |\n",
            "+---+------+----------------+-------------+---------------+------------+--------------+-------------------+-------------+---------------+-------------------+-----------------+---------------------+----------------------+--------------------------+----------------+--------------------+\n",
            "| 0 | 2020 | Andhra Pradesh | South India |   Anantapur   |    209     |     869      |         0         |    1078     |      32       |        177        |       284       |         585         |          0           |            0             |      316       |        762         |\n",
            "| 1 | 2020 | Andhra Pradesh | South India |   Chittoor    |    143     |     695      |         0         |     838     |      37       |        106        |       262       |         433         |          0           |            0             |      299       |        539         |\n",
            "| 2 | 2020 | Andhra Pradesh | South India |   Cuddapah    |    167     |     415      |         0         |     582     |      47       |        120        |       138       |         277         |          0           |            0             |      185       |        397         |\n",
            "| 3 | 2020 | Andhra Pradesh | South India | East Godavari |    311     |     515      |         0         |     826     |      40       |        271        |       125       |         390         |          0           |            0             |      165       |        661         |\n",
            "| 4 | 2020 | Andhra Pradesh | South India |    Guntur     |    232     |     410      |         0         |     642     |      61       |        171        |       111       |         299         |          0           |            0             |      172       |        470         |\n",
            "| 5 | 2020 | Andhra Pradesh | South India | Guntur Urban  |    151     |     281      |         0         |     432     |      30       |        121        |       77        |         204         |          0           |            0             |      107       |        325         |\n",
            "| 6 | 2020 | Andhra Pradesh | South India |    Krishna    |    199     |     333      |         0         |     532     |      33       |        166        |       37        |         296         |          0           |            0             |       70       |        462         |\n",
            "| 7 | 2020 | Andhra Pradesh | South India |    Kurnool    |    176     |     634      |         0         |     810     |      28       |        148        |       217       |         417         |          0           |            0             |      245       |        565         |\n",
            "| 8 | 2020 | Andhra Pradesh | South India |    Nellore    |    141     |     425      |         0         |     566     |      27       |        114        |       120       |         305         |          0           |            0             |      147       |        419         |\n",
            "| 9 | 2020 | Andhra Pradesh | South India |   Prakasham   |    164     |     371      |         0         |     535     |      53       |        111        |       85        |         286         |          0           |            0             |      138       |        397         |\n",
            "+---+------+----------------+-------------+---------------+------------+--------------+-------------------+-------------+---------------+-------------------+-----------------+---------------------+----------------------+--------------------------+----------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tabulate(dfs[3].head(10), headers='keys', tablefmt='pretty'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCdqS4RXnzne",
        "outputId": "40d3f8b6-f2d4-447e-d612-585b8e09b09f"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+----------------+-------------+---------------+------------+---------------+-------------------+--------------+-----------------+---------------------+-------------------+----------------------+--------------------------+-------------+----------------+--------------------+\n",
            "|   | Year |     State      |   Region    |   District    | Total_Male | Male_Below_18 | Male_18_and_above | Total_Female | Female_Below_18 | Female_18_and_above | Total_Transgender | Transgender_Below_18 | Transgender_18_and_above | Grand_Total | Total_Below_18 | Total_18_and_above |\n",
            "+---+------+----------------+-------------+---------------+------------+---------------+-------------------+--------------+-----------------+---------------------+-------------------+----------------------+--------------------------+-------------+----------------+--------------------+\n",
            "| 0 | 2021 | Andhra Pradesh | South India |   Anantapur   |    291     |      43       |        248        |     1224     |       446       |         778         |         0         |          0           |            0             |    1515     |      489       |        1026        |\n",
            "| 1 | 2021 | Andhra Pradesh | South India |   Chittoor    |    167     |      45       |        122        |     727      |       265       |         462         |         0         |          0           |            0             |     894     |      310       |        584         |\n",
            "| 2 | 2021 | Andhra Pradesh | South India |   Cuddapah    |    209     |      51       |        158        |     573      |       204       |         369         |        10         |          5           |            5             |     792     |      260       |        532         |\n",
            "| 3 | 2021 | Andhra Pradesh | South India | East Godavari |    353     |      29       |        324        |     693      |       191       |         502         |         0         |          0           |            0             |    1046     |      220       |        826         |\n",
            "| 4 | 2021 | Andhra Pradesh | South India |    Guntur     |    280     |      82       |        198        |     667      |       206       |         461         |         0         |          0           |            0             |     947     |      288       |        659         |\n",
            "| 5 | 2021 | Andhra Pradesh | South India | Guntur Urban  |    203     |      17       |        186        |     440      |       138       |         302         |         0         |          0           |            0             |     643     |      155       |        488         |\n",
            "| 6 | 2021 | Andhra Pradesh | South India |    Krishna    |    204     |      31       |        173        |     346      |       32        |         314         |         0         |          0           |            0             |     550     |       63       |        487         |\n",
            "| 7 | 2021 | Andhra Pradesh | South India |    Kurnool    |    299     |      93       |        206        |     865      |       261       |         604         |         0         |          0           |            0             |    1164     |      354       |        810         |\n",
            "| 8 | 2021 | Andhra Pradesh | South India |    Nellore    |    187     |      50       |        137        |     529      |       177       |         352         |         0         |          0           |            0             |     716     |      227       |        489         |\n",
            "| 9 | 2021 | Andhra Pradesh | South India |   Prakasham   |    191     |      53       |        138        |     575      |       198       |         377         |         0         |          0           |            0             |     766     |      251       |        515         |\n",
            "+---+------+----------------+-------------+---------------+------------+---------------+-------------------+--------------+-----------------+---------------------+-------------------+----------------------+--------------------------+-------------+----------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tabulate(dfs[4].head(10), headers='keys', tablefmt='pretty'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sQg7gayn1zM",
        "outputId": "0149be7e-e480-4543-aa74-612ec2027c57"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+----------------+-------------+--------------------------+------------+---------------+-------------------+--------------+-----------------+---------------------+-------------------+----------------------+--------------------------+-------------+----------------+--------------------+\n",
            "|   | Year |     State      |   Region    |         District         | Total_Male | Male_Below_18 | Male_18_and_above | Total_Female | Female_Below_18 | Female_18_and_above | Total_Transgender | Transgender_Below_18 | Transgender_18_and_above | Grand_Total | Total_Below_18 | Total_18_and_above |\n",
            "+---+------+----------------+-------------+--------------------------+------------+---------------+-------------------+--------------+-----------------+---------------------+-------------------+----------------------+--------------------------+-------------+----------------+--------------------+\n",
            "| 0 | 2022 | Andhra Pradesh | South India |  Alluri Sitharama Raju   |     36     |       8       |        28         |      80      |       54        |         26          |         1         |          0           |            1             |     117     |       62       |         55         |\n",
            "| 1 | 2022 | Andhra Pradesh | South India |        Anakapalli        |     89     |      20       |        69         |     197      |       56        |         141         |         0         |          0           |            0             |     286     |       76       |        210         |\n",
            "| 2 | 2022 | Andhra Pradesh | South India |       Anantapuramu       |    217     |      38       |        179        |     651      |       220       |         431         |         0         |          0           |            0             |     868     |      258       |        610         |\n",
            "| 3 | 2022 | Andhra Pradesh | South India |        Annamayya         |     91     |      31       |        60         |     292      |       135       |         157         |         0         |          0           |            0             |     383     |      166       |        217         |\n",
            "| 4 | 2022 | Andhra Pradesh | South India |         Bapatla          |    121     |      24       |        97         |     297      |       79        |         218         |         4         |          3           |            1             |     422     |      106       |        316         |\n",
            "| 5 | 2022 | Andhra Pradesh | South India |         Chittoor         |    114     |      18       |        96         |     538      |       177       |         361         |         0         |          0           |            0             |     652     |      195       |        457         |\n",
            "| 6 | 2022 | Andhra Pradesh | South India | Dr BR Ambedkar Konaseema |    165     |      23       |        142        |     267      |       77        |         190         |         0         |          0           |            0             |     432     |      100       |        332         |\n",
            "| 7 | 2022 | Andhra Pradesh | South India |      East Godavari       |    208     |      36       |        172        |     403      |       139       |         264         |         0         |          0           |            0             |     611     |      175       |        436         |\n",
            "| 8 | 2022 | Andhra Pradesh | South India |          Eluru           |    227     |      27       |        200        |     413      |       98        |         315         |         0         |          0           |            0             |     640     |      125       |        515         |\n",
            "| 9 | 2022 | Andhra Pradesh | South India |     Guntakal Railway     |     4      |       1       |         3         |      6       |        1        |          5          |         0         |          0           |            0             |     10      |       2        |         8          |\n",
            "+---+------+----------------+-------------+--------------------------+------------+---------------+-------------------+--------------+-----------------+---------------------+-------------------+----------------------+--------------------------+-------------+----------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Columns in the DataFrame:\")\n",
        "print(df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErvGKcp9n24g",
        "outputId": "a9bd5f64-017c-4591-e38f-5ba58e1dd74d"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in the DataFrame:\n",
            "['Year', 'State', 'Region', 'District', 'Total_Male', 'Male_Below_18', 'Male_18_and_above', 'Total_Female', 'Female_Below_18', 'Female_18_and_above', 'Total_Transgender', 'Transgender_Below_18', 'Transgender_18_and_above', 'Grand_Total', 'Total_Below_18', 'Total_18_and_above']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#   Data Pre-processing:\n",
        "1.      - Analysing dataset values\n",
        "2.      - Merging the datasets.\n",
        "2.     - Handling missing values and data type conversions."
      ],
      "metadata": {
        "id": "3y-lEaqGqhY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Columns in the DataFrame:\")\n",
        "print(df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAYFqyEZn_Mr",
        "outputId": "f70cecd1-a81a-4ac6-d347-7ac1186b50c8"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in the DataFrame:\n",
            "['Year', 'State', 'Region', 'District', 'Total_Male', 'Male_Below_18', 'Male_18_and_above', 'Total_Female', 'Female_Below_18', 'Female_18_and_above', 'Total_Transgender', 'Transgender_Below_18', 'Transgender_18_and_above', 'Grand_Total', 'Total_Below_18', 'Total_18_and_above']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate all dataframes into a single dataframe\n",
        "data = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Display combined dataframe shape and basic info\n",
        "print(\"Combined dataset shape:\", data.shape)\n",
        "print(\"\\nDataset Info:\")\n",
        "data.info()\n",
        "\n",
        "# Check for missing values in each column\n",
        "missing_values = data.isna().sum()\n",
        "print(\"\\nMissing Values per column:\\n\", missing_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn0ev-yIqkZK",
        "outputId": "c0af6b56-ce02-4d8f-d554-d46b09a1c630"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined dataset shape: (4646, 16)\n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4646 entries, 0 to 4645\n",
            "Data columns (total 16 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   Year                      4646 non-null   int64  \n",
            " 1   State                     4646 non-null   object \n",
            " 2   Region                    4646 non-null   object \n",
            " 3   District                  4646 non-null   object \n",
            " 4   Total_Male                4646 non-null   int64  \n",
            " 5   Total_Female              4646 non-null   int64  \n",
            " 6   Total_Transgender         4646 non-null   int64  \n",
            " 7   Grand_Total               4646 non-null   int64  \n",
            " 8   Male_Below_18             4646 non-null   int64  \n",
            " 9   Male_18_and_above         4646 non-null   float64\n",
            " 10  Female_Below_18           4646 non-null   int64  \n",
            " 11  Female_18_and_above       4646 non-null   float64\n",
            " 12  Transgender_Below_18      4646 non-null   int64  \n",
            " 13  Transgender_18_and_above  4646 non-null   int64  \n",
            " 14  Total_Below_18            4646 non-null   int64  \n",
            " 15  Total_18_and_above        4646 non-null   int64  \n",
            "dtypes: float64(2), int64(11), object(3)\n",
            "memory usage: 580.9+ KB\n",
            "\n",
            "Missing Values per column:\n",
            " Year                        0\n",
            "State                       0\n",
            "Region                      0\n",
            "District                    0\n",
            "Total_Male                  0\n",
            "Total_Female                0\n",
            "Total_Transgender           0\n",
            "Grand_Total                 0\n",
            "Male_Below_18               0\n",
            "Male_18_and_above           0\n",
            "Female_Below_18             0\n",
            "Female_18_and_above         0\n",
            "Transgender_Below_18        0\n",
            "Transgender_18_and_above    0\n",
            "Total_Below_18              0\n",
            "Total_18_and_above          0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YRxQntZPhwIm"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Concatenate your five processed DataFrames\n",
        "df_all = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Clean up whitespace\n",
        "df_all['State']    = df_all['State'].astype(str).str.strip()\n",
        "df_all['District'] = df_all['District'].astype(str).str.strip()\n",
        "\n",
        "\n",
        "# Ensuring consistent naming\n",
        "df_all['District'] = (\n",
        "    df_all['District']\n",
        "      .str.strip()\n",
        "      .str.replace(r'(?i)^total districts$', 'Total', regex=True)\n",
        ")\n",
        "df_all['District'] = (\n",
        "    df_all['District']\n",
        "      .str.strip()\n",
        "      .str.replace(r'(?i)^all districts$', 'Total', regex=True)\n",
        ")\n",
        "df_all['State'] = df_all['State'].str.strip().str.replace(r'(?i)^ladakh$', 'Kashmir', regex=True)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "btocYx_HyhF-"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fixing disrepancies in Andhra Pradesh district incostincencies\n",
        "# Correct “Anantapur” to “Anantapuramu”\n",
        "df_all['District'] = (\n",
        "    df_all['District']\n",
        "      .str.strip()\n",
        "      .str.replace(r'(?i)^anantapur$', 'Anantapuramu', regex=True)\n",
        ")\n",
        "\n",
        "# Correct “Cuddapah” to “YSR Kadapa”\n",
        "df_all['District'] = (\n",
        "    df_all['District']\n",
        "      .str.strip()\n",
        "      .str.replace(r'(?i)^cuddapah$', 'YSR Kadapa', regex=True)\n",
        ")\n",
        "# Correct “Cuddapah” to “YSR Kadapa”\n",
        "df_all['District'] = (\n",
        "    df_all['District']\n",
        "      .str.strip()\n",
        "      .str.replace(r'(?i)^ysr$', 'YSR Kadapa', regex=True)\n",
        ")\n",
        "\n",
        "# Correct “Prakasham” to “Prakasam”\n",
        "df_all['District'] = (\n",
        "    df_all['District']\n",
        "      .str.strip()\n",
        "      .str.replace(r'(?i)^prakasham$', 'Prakasam', regex=True)\n",
        ")\n",
        "df_all['District'] = df_all['District'].str.strip().str.replace(r'(?i)^nellore$', 'Sri Potti Sriramulu Nellore',regex=True)\n",
        "\n",
        "# Normalize “Tirupathi Urban” to “Tirupati”\n",
        "df_all['District'] = (\n",
        "    df_all['District']\n",
        "      .str.strip()\n",
        "      .str.replace(r'(?i)^tirupathi\\s+urban$', 'Tirupati', regex=True)\n",
        ")\n"
      ],
      "metadata": {
        "id": "IYkRTHYS2PwA"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Fixing disrepancies in the state of Sikkim\n",
        "# Apply only to rows where State is “Sikkim”\n",
        "mask_sikkim = df_all['State'] == 'Sikkim'\n",
        "\n",
        "# 3) Define your regex→replacement map\n",
        "district_patterns = {\n",
        "    r'(?i)\\(east\\)$':  'Gangtok',\n",
        "    r'(?i)\\(north\\)$': 'Mangan',\n",
        "    r'(?i)\\(south\\)$': 'Namchi',\n",
        "    r'(?i)\\(west\\)$':  'Soreng',\n",
        "}\n",
        "\n",
        "# 4) Apply it in one vectorized step\n",
        "df_all.loc[mask_sikkim, 'District'] = (\n",
        "    df_all.loc[mask_sikkim, 'District'].replace(district_patterns, regex=True)\n",
        ")\n",
        "\n",
        "# 5) (Optional) verify\n",
        "print(df_all[mask_sikkim & df_all['District'].isin(['Gangtok','Mangan','Namchi','Soreng'])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfKFSbmpLWzw",
        "outputId": "4746b13b-81c1-4532-8ba0-4f62d630e0dd"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [Year, State, Region, District, Total_Male, Total_Female, Total_Transgender, Grand_Total, Male_Below_18, Male_18_and_above, Female_Below_18, Female_18_and_above, Transgender_Below_18, Transgender_18_and_above, Total_Below_18, Total_18_and_above]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def unify_lucknow(df, years, jurisdictions):\n",
        "\n",
        "    df = df.copy()\n",
        "    # Identify data vs metadata columns\n",
        "    metadata_cols = ['State', 'Region', 'District', 'Year']\n",
        "    numeric_cols = df.columns.difference(metadata_cols)\n",
        "\n",
        "    # Mask for target rows\n",
        "    mask = df['Year'].isin(years) & df['District'].isin(jurisdictions)\n",
        "\n",
        "    # Reliability check: each year must contain exactly the specified jurisdictions\n",
        "    counts = df[mask].groupby('Year')['District'].nunique()\n",
        "    missing = {year: counts.get(year, 0) for year in years}\n",
        "    assert all(count == len(jurisdictions) for count in missing.values()), \\\n",
        "        f\"Expected {len(jurisdictions)} jurisdictions in each year; found {missing}\"\n",
        "\n",
        "    # Aggregate numeric columns to create unified 'Lucknow' rows\n",
        "    agg = (\n",
        "        df[mask]\n",
        "        .groupby(['Year', 'State', 'Region'], as_index=False)[numeric_cols]\n",
        "        .sum()\n",
        "    )\n",
        "    agg['District'] = 'Lucknow'\n",
        "\n",
        "    # Remove original jurisdiction rows and append the unified ones\n",
        "    df = df[~mask].reset_index(drop=True)\n",
        "    df = pd.concat([df, agg], ignore_index=True)\n",
        "\n",
        "    # Post-condition check: exactly one 'Lucknow' row per target year\n",
        "    for year in years:\n",
        "        count_lucknow = ((df['Year'] == year) & (df['District'] == 'Lucknow')).sum()\n",
        "        assert count_lucknow == 1, f\"Year {year} expected 1 'Lucknow' row, found {count_lucknow}\"\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply the function\n",
        "target_years = [2020, 2021, 2022]\n",
        "jurisdictions = ['Lucknow Commissionarate', 'Lucknow Grameen']\n",
        "\n",
        "df_all = unify_lucknow(df_all, target_years, jurisdictions)\n",
        "\n",
        "# Quick verification\n",
        "display(df_all[df_all['Year'].isin(target_years) & (df_all['District'] == 'Lucknow')])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "LmlDhZkpgk-g",
        "outputId": "142197d3-7adf-4655-fea8-ad1b43acbfc1"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      Year          State       Region District  Total_Male  Total_Female  \\\n",
              "4640  2020  Uttar Pradesh  North India  Lucknow         602           532   \n",
              "4641  2021  Uttar Pradesh  North India  Lucknow          30            16   \n",
              "4642  2022  Uttar Pradesh  North India  Lucknow         157           180   \n",
              "\n",
              "      Total_Transgender  Grand_Total  Male_Below_18  Male_18_and_above  \\\n",
              "4640                  0         1134            218              384.0   \n",
              "4641                  0           46             16               14.0   \n",
              "4642                  0          337            157                0.0   \n",
              "\n",
              "      Female_Below_18  Female_18_and_above  Transgender_Below_18  \\\n",
              "4640              218                314.0                     0   \n",
              "4641               16                  0.0                     0   \n",
              "4642              180                  0.0                     0   \n",
              "\n",
              "      Transgender_18_and_above  Total_Below_18  Total_18_and_above  \n",
              "4640                         0             436                 698  \n",
              "4641                         0              32                  14  \n",
              "4642                         0             337                   0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59ca46a4-6583-4a5d-828a-975120497181\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>State</th>\n",
              "      <th>Region</th>\n",
              "      <th>District</th>\n",
              "      <th>Total_Male</th>\n",
              "      <th>Total_Female</th>\n",
              "      <th>Total_Transgender</th>\n",
              "      <th>Grand_Total</th>\n",
              "      <th>Male_Below_18</th>\n",
              "      <th>Male_18_and_above</th>\n",
              "      <th>Female_Below_18</th>\n",
              "      <th>Female_18_and_above</th>\n",
              "      <th>Transgender_Below_18</th>\n",
              "      <th>Transgender_18_and_above</th>\n",
              "      <th>Total_Below_18</th>\n",
              "      <th>Total_18_and_above</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4640</th>\n",
              "      <td>2020</td>\n",
              "      <td>Uttar Pradesh</td>\n",
              "      <td>North India</td>\n",
              "      <td>Lucknow</td>\n",
              "      <td>602</td>\n",
              "      <td>532</td>\n",
              "      <td>0</td>\n",
              "      <td>1134</td>\n",
              "      <td>218</td>\n",
              "      <td>384.0</td>\n",
              "      <td>218</td>\n",
              "      <td>314.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>436</td>\n",
              "      <td>698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4641</th>\n",
              "      <td>2021</td>\n",
              "      <td>Uttar Pradesh</td>\n",
              "      <td>North India</td>\n",
              "      <td>Lucknow</td>\n",
              "      <td>30</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>16</td>\n",
              "      <td>14.0</td>\n",
              "      <td>16</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4642</th>\n",
              "      <td>2022</td>\n",
              "      <td>Uttar Pradesh</td>\n",
              "      <td>North India</td>\n",
              "      <td>Lucknow</td>\n",
              "      <td>157</td>\n",
              "      <td>180</td>\n",
              "      <td>0</td>\n",
              "      <td>337</td>\n",
              "      <td>157</td>\n",
              "      <td>0.0</td>\n",
              "      <td>180</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>337</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59ca46a4-6583-4a5d-828a-975120497181')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-59ca46a4-6583-4a5d-828a-975120497181 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-59ca46a4-6583-4a5d-828a-975120497181');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-84686d51-9bdb-49ed-8d67-573a630227b3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-84686d51-9bdb-49ed-8d67-573a630227b3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-84686d51-9bdb-49ed-8d67-573a630227b3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_all[df_all['Year']\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2020,\n        \"max\": 2022,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2020,\n          2021,\n          2022\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"State\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Uttar Pradesh\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Region\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"North India\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"District\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Lucknow\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total_Male\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 300,\n        \"min\": 30,\n        \"max\": 602,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          602\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total_Female\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 263,\n        \"min\": 16,\n        \"max\": 532,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          532\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total_Transgender\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Grand_Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 563,\n        \"min\": 46,\n        \"max\": 1134,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1134\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Male_Below_18\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 103,\n        \"min\": 16,\n        \"max\": 218,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          218\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Male_18_and_above\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 217.7735827260353,\n        \"min\": 0.0,\n        \"max\": 384.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          384.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Female_Below_18\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 107,\n        \"min\": 16,\n        \"max\": 218,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          218\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Female_18_and_above\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 181.28798452554247,\n        \"min\": 0.0,\n        \"max\": 314.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Transgender_Below_18\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Transgender_18_and_above\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total_Below_18\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 210,\n        \"min\": 32,\n        \"max\": 436,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          436\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total_18_and_above\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 399,\n        \"min\": 0,\n        \"max\": 698,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          698\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def unify_district(df, state, jurisdictions, new_name, years):\n",
        "    \"\"\"\n",
        "    Merge specified jurisdictions into a single district for given state and years.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): Original DataFrame.\n",
        "        state (str): State name to filter on.\n",
        "        jurisdictions (list of str): List of district names to merge.\n",
        "        new_name (str): New district name after merge.\n",
        "        years (list of int): Years to apply the merge.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with merged district entries.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    # Identify metadata vs numeric columns\n",
        "    metadata_cols = ['State', 'Region', 'District', 'Year']\n",
        "    numeric_cols = df.columns.difference(metadata_cols)\n",
        "\n",
        "    # Mask for target rows\n",
        "    mask = (\n",
        "        (df['State'] == state) &\n",
        "        (df['Year'].isin(years)) &\n",
        "        (df['District'].isin(jurisdictions))\n",
        "    )\n",
        "\n",
        "    # Ensure each year has all jurisdictions present\n",
        "    year_counts = df[mask].groupby('Year')['District'].nunique()\n",
        "    missing = {year: year_counts.get(year, 0) for year in years}\n",
        "    assert all(count == len(jurisdictions) for count in missing.values()), \\\n",
        "        f\"Expected {len(jurisdictions)} jurisdictions in each year; found {missing}\"\n",
        "\n",
        "    # Aggregate numeric features\n",
        "    agg = (\n",
        "        df[mask]\n",
        "        .groupby(['Year', 'State', 'Region'], as_index=False)[numeric_cols]\n",
        "        .sum()\n",
        "    )\n",
        "    agg['District'] = new_name\n",
        "\n",
        "    # Remove original rows and append unified rows\n",
        "    df = df[~mask].reset_index(drop=True)\n",
        "    df = pd.concat([df, agg], ignore_index=True)\n",
        "\n",
        "    # Post-check: exactly one new district per year\n",
        "    for year in years:\n",
        "        count_new = ((df['Year'] == year) & (df['District'] == new_name)).sum()\n",
        "        assert count_new == 1, f\"Year {year}: expected 1 '{new_name}' row, found {count_new}\"\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply for Kerala: combine 'Kannur City' + 'Kannur Rural' into 'Kannur' for 2021 and 2022\n",
        "df_all = unify_district(\n",
        "    df_all,\n",
        "    state='Kerala',\n",
        "    jurisdictions=['Kannur City', 'Kannur Rural'],\n",
        "    new_name='Kannur',\n",
        "    years=[2021, 2022]\n",
        ")\n",
        "\n",
        "# Verify the merge\n",
        "display(df_all[(df_all['State'] == 'Kerala') &\n",
        "               (df_all['Year'].isin([2021, 2022])) &\n",
        "               (df_all['District'] == 'Kannur')])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "izzfqGohhyug",
        "outputId": "c39f04c1-bc44-4cce-a785-92588413fd32"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      Year   State       Region District  Total_Male  Total_Female  \\\n",
              "4639  2021  Kerala  South India   Kannur         114           232   \n",
              "4640  2022  Kerala  South India   Kannur         184           254   \n",
              "\n",
              "      Total_Transgender  Grand_Total  Male_Below_18  Male_18_and_above  \\\n",
              "4639                  0          346             18               96.0   \n",
              "4640                  0          438             45              139.0   \n",
              "\n",
              "      Female_Below_18  Female_18_and_above  Transgender_Below_18  \\\n",
              "4639               34                198.0                     0   \n",
              "4640               45                209.0                     0   \n",
              "\n",
              "      Transgender_18_and_above  Total_Below_18  Total_18_and_above  \n",
              "4639                         0              52                 294  \n",
              "4640                         0              90                 348  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c326905-6338-45bc-852a-689ca3f43cbb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>State</th>\n",
              "      <th>Region</th>\n",
              "      <th>District</th>\n",
              "      <th>Total_Male</th>\n",
              "      <th>Total_Female</th>\n",
              "      <th>Total_Transgender</th>\n",
              "      <th>Grand_Total</th>\n",
              "      <th>Male_Below_18</th>\n",
              "      <th>Male_18_and_above</th>\n",
              "      <th>Female_Below_18</th>\n",
              "      <th>Female_18_and_above</th>\n",
              "      <th>Transgender_Below_18</th>\n",
              "      <th>Transgender_18_and_above</th>\n",
              "      <th>Total_Below_18</th>\n",
              "      <th>Total_18_and_above</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4639</th>\n",
              "      <td>2021</td>\n",
              "      <td>Kerala</td>\n",
              "      <td>South India</td>\n",
              "      <td>Kannur</td>\n",
              "      <td>114</td>\n",
              "      <td>232</td>\n",
              "      <td>0</td>\n",
              "      <td>346</td>\n",
              "      <td>18</td>\n",
              "      <td>96.0</td>\n",
              "      <td>34</td>\n",
              "      <td>198.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4640</th>\n",
              "      <td>2022</td>\n",
              "      <td>Kerala</td>\n",
              "      <td>South India</td>\n",
              "      <td>Kannur</td>\n",
              "      <td>184</td>\n",
              "      <td>254</td>\n",
              "      <td>0</td>\n",
              "      <td>438</td>\n",
              "      <td>45</td>\n",
              "      <td>139.0</td>\n",
              "      <td>45</td>\n",
              "      <td>209.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>90</td>\n",
              "      <td>348</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c326905-6338-45bc-852a-689ca3f43cbb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c326905-6338-45bc-852a-689ca3f43cbb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c326905-6338-45bc-852a-689ca3f43cbb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d07ee606-9b6b-40c9-a398-eaa9a9edaeb8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d07ee606-9b6b-40c9-a398-eaa9a9edaeb8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d07ee606-9b6b-40c9-a398-eaa9a9edaeb8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"               (df_all['District'] == 'Kannur')])\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2021,\n        \"max\": 2022,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2022,\n          2021\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"State\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Kerala\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Region\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"South India\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"District\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Kannur\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total_Male\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49,\n        \"min\": 114,\n        \"max\": 184,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          184\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total_Female\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 232,\n        \"max\": 254,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          254\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total_Transgender\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Grand_Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 65,\n        \"min\": 346,\n        \"max\": 438,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          438\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Male_Below_18\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 18,\n        \"max\": 45,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Male_18_and_above\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.405591591021544,\n        \"min\": 96.0,\n        \"max\": 139.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          139.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Female_Below_18\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 34,\n        \"max\": 45,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Female_18_and_above\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.7781745930520225,\n        \"min\": 198.0,\n        \"max\": 209.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          209.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Transgender_Below_18\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Transgender_18_and_above\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total_Below_18\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26,\n        \"min\": 52,\n        \"max\": 90,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          90\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total_18_and_above\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 38,\n        \"min\": 294,\n        \"max\": 348,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          348\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize “Bhabhua” to “Kaimur”\n",
        "df_all['District'] = (\n",
        "    df_all['District']\n",
        "      .str.strip()\n",
        "      .str.replace(r'(?i)^bhabhua$', 'Kaimur', regex=True)\n",
        ")\n",
        "\n",
        "# Normalize “Varanasi Commissionarate” to “Varanasi”\n",
        "df_all['District'] = (\n",
        "    df_all['District']\n",
        "      .str.strip()\n",
        "      .str.replace(r'(?i)^varanasi+commissionarate$', 'Varanasi', regex=True)\n",
        ")\n",
        "# Normalize “Murshidabad Police District” to “Murshidabad”\n",
        "df_all['District'] = (\n",
        "    df_all['District']\n",
        "      .str.strip()\n",
        "      .str.replace(\n",
        "          r'(?i)^murshidabad\\s+police\\s+district$',\n",
        "          'Murshidabad',\n",
        "          regex=True\n",
        "      )\n",
        ")\n",
        "# Normalize “Hoshangabad” to “Narmadapuram” in Madhya Pradesh\n",
        "df_all['District'] = (\n",
        "    df_all['District']\n",
        "      .str.strip()\n",
        "      .str.replace(r'(?i)^hoshangabad$', 'Narmadapuram', regex=True)\n",
        ")\n"
      ],
      "metadata": {
        "id": "gyip4SfLTVkw"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the mask for 2022 and the two Indore jurisdictions\n",
        "mask_2022_indore = (\n",
        "    (df_all['Year'] == 2022) &\n",
        "    df_all['District'].isin(['Indore Commissionarate', 'Indore Rural'])\n",
        ")\n",
        "\n",
        "# Identify numeric columns (everything except these four)\n",
        "numeric_cols = df_all.columns.difference(['State', 'Region', 'District', 'Year'])\n",
        "\n",
        "# Sum the numeric values for those rows\n",
        "sums = df_all.loc[mask_2022_indore, numeric_cols].sum()\n",
        "\n",
        "# Build the new “Indore” row\n",
        "new_row = {\n",
        "    'State': 'Madhya Pradesh',\n",
        "    'Year': 2022,\n",
        "    'District': 'Indore',\n",
        "    **sums.to_dict()\n",
        "}\n",
        "\n",
        "# Remove the original two rows for 2022 Indore\n",
        "df_all = df_all.loc[~mask_2022_indore]\n",
        "\n",
        "# Append the aggregated Indore row\n",
        "df_all = pd.concat([df_all, pd.DataFrame([new_row])], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "TUeSzEdBj6J4"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Compute, for each row, the number of unique years its (State,District) appears in\n",
        "df_all['Year_count'] = (\n",
        "    df_all\n",
        "      .groupby(['State','District'])['Year']\n",
        "      .transform('nunique')\n",
        ")\n",
        "\n",
        "# Split into common vs non‑common\n",
        "common_df     = df_all[df_all['Year_count'] == 5].drop(columns='Year_count')\n",
        "non_common_df = df_all[df_all['Year_count'] <  5].drop(columns='Year_count')\n",
        "\n",
        "#  Save to CSV\n",
        "common_df.to_csv('districts_in_all_5_years.csv',     index=False)\n",
        "non_common_df.to_csv('districts_not_in_all_5_years.csv', index=False)\n",
        "\n",
        "print(f\"Common districts rows: {common_df.shape[0]}\")\n",
        "print(f\"Non‑common districts rows: {non_common_df.shape[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTdpFm8OwmYV",
        "outputId": "f240b075-1ddc-418d-c9a8-4ac469d5296a"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Common districts rows: 4327\n",
            "Non‑common districts rows: 314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display all rows that have at least one missing value\n",
        "rows_with_missing = data[data.isna().any(axis=1)]\n",
        "print(\"\\nRows with missing values:\")\n",
        "print(rows_with_missing)\n",
        "\n",
        "# Create a new DataFrame by removing rows with missing values\n",
        "data_clean = data.dropna()\n",
        "data_clean.shape\n",
        "data_clean.to_csv(\"data_clean.csv\", index=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybl03C5AqmIZ",
        "outputId": "8d2e8d34-e57a-4d66-d955-f5f869cf422e"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Rows with missing values:\n",
            "Empty DataFrame\n",
            "Columns: [Year, State, Region, District, Total_Male, Total_Female, Total_Transgender, Grand_Total, Male_Below_18, Male_18_and_above, Female_Below_18, Female_18_and_above, Transgender_Below_18, Transgender_18_and_above, Total_Below_18, Total_18_and_above]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#   Exploratory Data Analysis:\n",
        "1.      - Statistical summary.\n",
        "2.      - Distribution of key variables.\n",
        "3.     - Trends across years and per district.\n",
        "4.     - Visualizations with appropriate parameters.\n"
      ],
      "metadata": {
        "id": "BiHmCU-Er5ZO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0lxBqU2pqtuW"
      },
      "execution_count": 179,
      "outputs": []
    }
  ]
}