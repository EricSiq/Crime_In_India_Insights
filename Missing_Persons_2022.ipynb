{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EricSiq/Crime_In_India_Insights/blob/main/Missing_Persons_2022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Problem Statement & Objective\n",
        "\n"
      ],
      "metadata": {
        "id": "103XP1mE1inD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project analyzes district-wise missing persons data in India for the year 2022. Using unsupervised learning techniques, we aim to uncover regional patterns, detect anomalies, and visualize clusters. The dataset includes demographic breakdowns by gender and age group across states and union territories.\n",
        "\n"
      ],
      "metadata": {
        "id": "2u9YyCEI12hs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Importing Essential Libraries"
      ],
      "metadata": {
        "id": "Ck9Z6dR119Kt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.manifold import TSNE, MDS\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.patches as mpatches\n",
        "import umap\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "3aEI0kfo1-rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Load the Dataset"
      ],
      "metadata": {
        "id": "vACOrW9z2V0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path to the dataset\n",
        "file_path = '/content/DistrictwiseMissingPersons2022.csv'\n",
        "\n",
        "# Try loading the CSV file\n",
        "try:\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(\"Data loaded successfully!\")\n",
        "    print(\"Dataset shape:\", df.shape)\n",
        "    display(df.head())\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {file_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "6iP4fvWs2RWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Data Preprocessing"
      ],
      "metadata": {
        "id": "iRdBvKCI2hh_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.1 Region Mapping"
      ],
      "metadata": {
        "id": "Z4Y3bJvs2mTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to map states to regions\n",
        "def map_region(state):\n",
        "    south = [\"Andhra Pradesh\", \"Telangana\", \"Karnataka\", \"Tamil Nadu\", \"Kerala\", \"Puducherry\", \"Lakshadweep\", \"AN Islands\"]\n",
        "    west = [\"Maharashtra\", \"Goa\", \"Gujarat\", \"Daman and Diu\", \"DN Haveli and Daman Diu\"]\n",
        "    northeast = [\"Arunachal Pradesh\", \"Assam\", \"Manipur\", \"Meghalaya\", \"Mizoram\", \"Nagaland\", \"Tripura\", \"Sikkim\"]\n",
        "    north = [\"Kashmir\", \"Himachal Pradesh\", \"Punjab\", \"Uttarakhand\", \"Haryana\", \"Uttar Pradesh\", \"Rajasthan\", \"Bihar\",\n",
        "             \"Chhattisgarh\", \"West Bengal\", \"Odisha\", \"Chandigarh\", \"Delhi\", \"Ladakh\", \"Jharkhand\", \"Madhya Pradesh\"]\n",
        "\n",
        "    if state.strip() in south:\n",
        "        return \"South India\"\n",
        "    elif state.strip() in west:\n",
        "        return \"West Coast\"\n",
        "    elif state.strip() in northeast:\n",
        "        return \"North East\"\n",
        "    elif state.strip() in north:\n",
        "        return \"North India\"\n",
        "    else:\n",
        "        return \"Other\"\n",
        "\n",
        "# Apply region mapping to the dataset\n",
        "df['Region'] = df['State'].apply(map_region)\n"
      ],
      "metadata": {
        "id": "fubyd32w2hHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.2 Filter Rows"
      ],
      "metadata": {
        "id": "kVebiR342xNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove leading/trailing spaces in district names\n",
        "df['District'] = df['District'].str.strip()\n",
        "\n",
        "# Split into two datasets: all districts and the summary row\n",
        "total_districts = df[df['District'] == \"Total Districts\"]\n",
        "all_districts = df[df['District'] != \"Total Districts\"]\n",
        "\n",
        "# Display shapes of the two datasets\n",
        "print(\"Total Districts shape:\", total_districts.shape)\n",
        "print(\"All Districts shape:\", all_districts.shape)\n"
      ],
      "metadata": {
        "id": "L96TCcxP2uxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Scaling the Data"
      ],
      "metadata": {
        "id": "qQNyl8vq24ga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Select numeric columns for scaling\n",
        "numeric_cols_total = total_districts.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Create a copy and scale the data\n",
        "total_districts_scaled = total_districts.copy()\n",
        "total_districts_scaled[numeric_cols_total] = scaler.fit_transform(total_districts_scaled[numeric_cols_total])\n"
      ],
      "metadata": {
        "id": "ybWEMQKA2b36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. EDA (Exploratory Data Analysis)."
      ],
      "metadata": {
        "id": "eNkxFBwA3Bej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.1 Outlier Check Using Boxplots"
      ],
      "metadata": {
        "id": "QqaS4gtb3Kv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot boxplot for scaled numeric features\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.boxplot(data=total_districts_scaled[numeric_cols_total])\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Outlier Check - Total Districts\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qqyXd8mG3NoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.2 Distribution Plots for Scaled Features"
      ],
      "metadata": {
        "id": "9uwGGzmt3WAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# Calculate layout\n",
        "n_cols = len(numeric_cols_total)\n",
        "n_rows = math.ceil(n_cols / 4)\n",
        "\n",
        "# Plot all distributions\n",
        "plt.figure(figsize=(16, n_rows * 4))\n",
        "for i, col in enumerate(numeric_cols_total):\n",
        "    plt.subplot(n_rows, 4, i + 1)\n",
        "    sns.histplot(total_districts_scaled[col], kde=True, bins=20, color='skyblue')\n",
        "    plt.title(f'Distribution of {col}')\n",
        "    plt.tight_layout()\n",
        "\n",
        "plt.suptitle(\"Distribution of Features (Total Districts)\", fontsize=18)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-UVg3oVv3YnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Splitting Data into Train and Test Sets"
      ],
      "metadata": {
        "id": "WI3YHIJQ3ioa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Features (X) and Labels (y)\n",
        "X = total_districts_scaled[numeric_cols_total]\n",
        "y = total_districts['Region']\n",
        "\n",
        "# 80:20 split for training and testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "ZM5H_gcZ3epf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.1 Remove Underrepresented Classes\n",
        "Classes with less than 3 samples cause issues in both training and evaluation."
      ],
      "metadata": {
        "id": "wcNipr2Y-Vj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop classes with fewer than 3 samples\n",
        "value_counts = y_train.value_counts()\n",
        "valid_classes = value_counts[value_counts >= 3].index\n",
        "\n",
        "X_train_filtered = X_train[y_train.isin(valid_classes)]\n",
        "y_train_filtered = y_train[y_train.isin(valid_classes)]\n",
        "X_test_filtered = X_test[y_test.isin(valid_classes)]\n",
        "y_test_filtered = y_test[y_test.isin(valid_classes)]\n"
      ],
      "metadata": {
        "id": "9DrRUmJb-QI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. PCA - Principal Component Analysis"
      ],
      "metadata": {
        "id": "xanM_ph53pdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply PCA without limiting components\n",
        "pca_full = PCA()\n",
        "X_train_pca_full = pca_full.fit_transform(X_train)\n",
        "\n",
        "# Plot cumulative explained variance\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(np.cumsum(pca_full.explained_variance_ratio_), marker='o', linestyle='--', color='darkblue')\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.title('Explained Variance by PCA Components')\n",
        "plt.grid(True)\n",
        "plt.axhline(y=0.9, color='red', linestyle='--', label='90% Variance')\n",
        "plt.axhline(y=0.95, color='green', linestyle='--', label='95% Variance')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ocVvU5wu3mBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply PCA\n",
        "pca = PCA(n_components=5)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# Check explained variance\n",
        "print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)\n",
        "print(\"Total Explained Variance (5 components):\", pca.explained_variance_ratio_.sum())\n"
      ],
      "metadata": {
        "id": "4bxsBWo83-2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  9. LDA – Linear Discriminant Analysis"
      ],
      "metadata": {
        "id": "2pzAmhaR4VMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda = LDA(n_components=1)  # Max components = number of classes - 1 (we have 4 regions → max = 3)\n",
        "X_train_lda = lda.fit_transform(X_train, y_train)\n",
        "X_test_lda = lda.transform(X_test)\n",
        "\n",
        "# Pad with zeros to make it 2D for plotting later\n",
        "X_train_lda = np.hstack([X_train_lda, np.zeros_like(X_train_lda)])\n",
        "X_test_lda = np.hstack([X_test_lda, np.zeros_like(X_test_lda)])\n"
      ],
      "metadata": {
        "id": "ST9yeBMl4GXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_full = LDA(n_components=None)\n",
        "lda_full.fit(X_train, y_train)\n",
        "print(\"LDA Explained Variance Ratio:\", lda_full.explained_variance_ratio_)\n"
      ],
      "metadata": {
        "id": "EUyUB8Ag4sSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. SVD"
      ],
      "metadata": {
        "id": "G1KifXZW5JNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trying more components initially to observe explained variance\n",
        "svd_check = TruncatedSVD(n_components=10, random_state=42)\n",
        "svd_check.fit(X_train)\n",
        "\n",
        "explained_variance_svd = svd_check.explained_variance_ratio_.cumsum()\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, len(explained_variance_svd) + 1), explained_variance_svd, marker='o', linestyle='--', color='orange')\n",
        "plt.title('SVD - Cumulative Explained Variance')\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Cumulative Variance Explained')\n",
        "plt.grid(True)\n",
        "plt.axhline(y=0.90, color='red', linestyle='--', label='90% Threshold')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9HD3Pv5E5Mzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final SVD for visualization\n",
        "svd = TruncatedSVD(n_components=2, random_state=42)\n",
        "X_train_svd = svd.fit_transform(X_train)\n",
        "X_test_svd = svd.transform(X_test)\n"
      ],
      "metadata": {
        "id": "lf4_Dnpe5ewS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. MDS"
      ],
      "metadata": {
        "id": "unkJYBoM5kRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "mds = MDS(n_components=2, random_state=42, n_init=1, max_iter=300, dissimilarity='euclidean')\n",
        "X_train_mds = mds.fit_transform(X_train)\n",
        "X_test_mds = mds.fit_transform(X_test)\n",
        "\n",
        "# Reset y_train and y_test indices to match transformed arrays\n",
        "y_train_mds = y_train.reset_index(drop=True)\n",
        "y_test_mds = y_test.reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "HN-9dlAx5f2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. T-SNE"
      ],
      "metadata": {
        "id": "yFy_iRB-5tYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set perplexity based on data size\n",
        "perplexity = min(5, X_train.shape[0] - 1)\n",
        "\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity, max_iter=1000)\n",
        "X_train_tsne = tsne.fit_transform(X_train)\n",
        "X_test_tsne = tsne.fit_transform(X_test)\n",
        "\n",
        "# Reset indices for matching\n",
        "y_train_tsne = y_train.reset_index(drop=True)\n",
        "y_test_tsne = y_test.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "J4bpg_qI6XeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13. UMap\n"
      ],
      "metadata": {
        "id": "8btCUlmU6Zap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "umap_model = umap.UMAP(n_components=2, random_state=42)\n",
        "\n",
        "# Fit and transform\n",
        "X_train_umap = umap_model.fit_transform(X_train)\n",
        "X_test_umap = umap_model.transform(X_test)"
      ],
      "metadata": {
        "id": "dNeONBdd6hr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13.1 Clustering on UMap"
      ],
      "metadata": {
        "id": "a-uoH_RU6zkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "inertia = []\n",
        "silhouette_scores = []\n",
        "K_range = range(2, 11)\n",
        "\n",
        "for k in K_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(X_train_umap)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "    score = silhouette_score(X_train_umap, kmeans.labels_)\n",
        "    silhouette_scores.append(score)\n",
        "\n",
        "# Plot Inertia (Elbow Method)\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(K_range, inertia, 'o-')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Inertia')\n",
        "plt.title('Elbow Method for Optimal k')\n",
        "\n",
        "# Plot Silhouette Score\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(K_range, silhouette_scores, 's-', color='green')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Score vs. k')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "njJ1QK3F6rug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Perform KMeans clustering\n",
        "kmeans = KMeans(n_clusters=4, random_state=42)\n",
        "umap_clusters = kmeans.fit_predict(X_train_umap)\n",
        "\n",
        "# Add cluster labels to a DataFrame for visualization\n",
        "umap_cluster_df = pd.DataFrame(X_train_umap, columns=['UMAP1', 'UMAP2'])\n",
        "umap_cluster_df['Cluster'] = umap_clusters\n",
        "\n",
        "# Plot the clusters\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(data=umap_cluster_df, x='UMAP1', y='UMAP2', hue='Cluster', palette='Set2', s=60)\n",
        "plt.title(\"KMeans Clustering (k=4) on UMAP Output\")\n",
        "plt.xlabel(\"UMAP Component 1\")\n",
        "plt.ylabel(\"UMAP Component 2\")\n",
        "plt.legend(title=\"Cluster\")\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5_0gyEMr8vAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14. Comparative Visualization of Dimensionality Reduction Methods"
      ],
      "metadata": {
        "id": "YFodRQnf89Tb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Create label-to-color mapping\n",
        "unique_labels = sorted(y_train.unique())\n",
        "label_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "colors = sns.color_palette(\"tab10\", len(unique_labels))\n",
        "color_map = {label: colors[idx] for label, idx in label_mapping.items()}\n",
        "legend_handles = [mpatches.Patch(color=color_map[label], label=label) for label in unique_labels]\n",
        "\n",
        "# Data to plot\n",
        "method_names = [\"PCA\", \"SVD\", \"t-SNE\", \"MDS\", \"UMAP\"]\n",
        "method_data = [X_train_pca, X_train_svd, X_train_tsne, X_train_mds, X_train_umap]\n",
        "\n",
        "# Plotting\n",
        "fig, axes = plt.subplots(2, 3, figsize=(20, 10), constrained_layout=True)\n",
        "fig.suptitle(\"2D Visualization of Dimensionality Reduction Methods\", fontsize=20, fontweight=\"bold\", color=\"darkred\")\n",
        "\n",
        "for ax, data, name in zip(axes.flat, method_data, method_names):\n",
        "    for label in unique_labels:\n",
        "        idxs = y_train == label\n",
        "        ax.scatter(\n",
        "            data[idxs, 0], data[idxs, 1],\n",
        "            color=color_map[label], label=label, edgecolors='white', linewidth=0.5, s=40, alpha=0.9\n",
        "        )\n",
        "    ax.set_title(name, fontsize=16, fontweight=\"bold\")\n",
        "    ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "    ax.set_xlabel(\"Component 1\")\n",
        "    ax.set_ylabel(\"Component 2\")\n",
        "\n",
        "# Turn off extra subplot if any\n",
        "if len(method_data) < len(axes.flat):\n",
        "    axes.flat[-1].axis('off')\n",
        "\n",
        "# Add legend\n",
        "fig.legend(handles=legend_handles, loc='lower right', bbox_to_anchor=(0.93, 0.93), fontsize=12, title=\"Regions\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "3iXWUvia9APN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 15.Model Evaluation"
      ],
      "metadata": {
        "id": "f8xaYGyZ9N4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def tune_knn(X_train_red, y_train_red, X_test_red, y_test_red, method=\"KNN\"):\n",
        "    param_grid = {\n",
        "        'n_neighbors': [3, 5, 7, 9],\n",
        "        'weights': ['uniform', 'distance'],\n",
        "        'p': [1, 2]  # Manhattan and Euclidean distances\n",
        "    }\n",
        "\n",
        "    model = KNeighborsClassifier()\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "    grid_search.fit(X_train_red, y_train_red)\n",
        "\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_pred = best_model.predict(X_test_red)\n",
        "\n",
        "    acc = accuracy_score(y_test_red, y_pred)\n",
        "    class_report = classification_report(y_test_red, y_pred, zero_division=1)\n",
        "    conf_matrix = confusion_matrix(y_test_red, y_pred)\n",
        "    best_params = grid_search.best_params_\n",
        "\n",
        "    print(f\"{method} Tuned Accuracy: {acc:.4f}\")\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": acc,\n",
        "        \"classification_report\": class_report,\n",
        "        \"confusion_matrix\": conf_matrix,\n",
        "        \"best_params\": best_params\n",
        "    }\n"
      ],
      "metadata": {
        "id": "JNZe0a9s9M79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_knn = {}\n",
        "results_knn['PCA'] = tune_knn(X_train_pca, y_train, X_test_pca, y_test, method=\"PCA + KNN\")\n",
        "results_knn['LDA'] = tune_knn(X_train_lda, y_train, X_test_lda, y_test, method=\"LDA + KNN\")\n",
        "results_knn['SVD'] = tune_knn(X_train_svd, y_train, X_test_svd, y_test, method=\"SVD + KNN\")\n",
        "results_knn['MDS'] = tune_knn(X_train_mds, y_train_mds, X_test_mds, y_test_mds, method=\"MDS + KNN\")\n",
        "results_knn['t-SNE'] = tune_knn(X_train_tsne, y_train_tsne, X_test_tsne, y_test_tsne, method=\"t-SNE + KNN\")\n"
      ],
      "metadata": {
        "id": "PXgavtpn9aMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = {method: result[\"accuracy\"] for method, result in results.items()}\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(accuracies.keys(), accuracies.values(), color='skyblue')\n",
        "plt.xlabel(\"Dimensionality Reduction Method\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Model Performance Comparison\")\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QWD7gszl9xxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for method, result in results_knn.items():\n",
        "    print(f\"{method} Accuracy: {result['accuracy']:.4f}\")\n",
        "    print(f\"Best Params: {result['best_params']}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "3VcYdW7h9y8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for method, result in results_knn.items():\n",
        "    print(f\"{method} Classification Report:\\n{result['classification_report']}\\n\")\n"
      ],
      "metadata": {
        "id": "8XK4R2KW_UFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for method, result in results_knn.items():\n",
        "    print(f\"{method} Confusion Matrix:\\n{result['confusion_matrix']}\\n\")\n"
      ],
      "metadata": {
        "id": "GKxEV6Wy_X1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for method, result in results_knn.items():\n",
        "    print(f\"{method} Confusion Matrix:\\n{result['confusion_matrix']}\\n\")\n"
      ],
      "metadata": {
        "id": "0yHblFF9_cHW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}